{"cells":[{"cell_type":"code","source":["# 连接谷歌云盘\n","from google.colab import drive\n","import os\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-fardzzvteJn","executionInfo":{"status":"ok","timestamp":1690249767219,"user_tz":-480,"elapsed":3397,"user":{"displayName":"沫茶子","userId":"03946290060744434733"}},"outputId":"9c5f1238-1c57-402b-d75e-10edc5757c5e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14660,"status":"ok","timestamp":1690249108209,"user":{"displayName":"沫茶子","userId":"03946290060744434733"},"user_tz":-480},"id":"FaEw40F7afRH","outputId":"efa95e30-7751-4431-da42-c4d07b304169"},"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA可使用\n","驱动为： cuda:0\n","GPU型号:  Tesla T4\n","2.0.1+cu118\n","True\n","cpu 0.5979037284851074 tensor(141379.)\n","cuda:0 2.7379791736602783 tensor(141522.4688, device='cuda:0')\n","cuda:0 0.0006482601165771484 tensor(141522.4688, device='cuda:0')\n"]}],"source":["# 测试torch、cuda环境\n","import torch\n","flag = torch.cuda.is_available()\n","if flag:\n","    print(\"CUDA可使用\")\n","else:\n","    print(\"CUDA不可用\")\n","\n","ngpu= 1\n","# Decide which device we want to run on\n","device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n","print(\"驱动为：\",device)\n","print(\"GPU型号: \",torch.cuda.get_device_name(0))\n","\n","import \ttorch\n","import  time\n","print(torch.__version__)\n","print(torch.cuda.is_available())\n","# print('hello, world.')\n","\n","\n","a = torch.randn(10000, 1000)\n","b = torch.randn(1000, 2000)\n","\n","t0 = time.time()\n","c = torch.matmul(a, b)\n","t1 = time.time()\n","print(a.device, t1 - t0, c.norm(2))\n","\n","device = torch.device('cuda')\n","a = a.to(device)\n","b = b.to(device)\n","\n","t0 = time.time()\n","c = torch.matmul(a, b)\n","t2 = time.time()\n","print(a.device, t2 - t0, c.norm(2))\n","\n","t0 = time.time()\n","c = torch.matmul(a, b)\n","t2 = time.time()\n","print(a.device, t2 - t0, c.norm(2))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":429,"status":"ok","timestamp":1690249120735,"user":{"displayName":"沫茶子","userId":"03946290060744434733"},"user_tz":-480},"id":"JptTJkufa1_L","outputId":"deb5935e-9e8c-433a-dc76-70e8909fcdb6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Jul 25 01:38:42 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   47C    P0    28W /  70W |   1009MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}],"source":["# 检测NVIDIA驱动\n","!nvidia-smi"]},{"cell_type":"code","source":["#安装第三方库\n","!pip3 install fire loguru pyyaml tqdm numpy pillow onnx"],"metadata":{"id":"fLhCo2egw-2x","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690688147218,"user_tz":-480,"elapsed":8626,"user":{"displayName":"沫茶子","userId":"03946290060744434733"}},"outputId":"07c540fa-843e-42bd-cc1d-7c9ec390966e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting fire\n","  Downloading fire-0.5.0.tar.gz (88 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting loguru\n","  Downloading loguru-0.7.0-py3-none-any.whl (59 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (6.0.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.65.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.22.4)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n","Collecting onnx\n","  Downloading onnx-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire) (1.16.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire) (2.3.0)\n","Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n","Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx) (4.7.1)\n","Building wheels for collected packages: fire\n","  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116932 sha256=4834f0829f8f615efb89b9879b9dc2e80ef969d89d7834b88a6b04eb394d658b\n","  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n","Successfully built fire\n","Installing collected packages: onnx, loguru, fire\n","Successfully installed fire-0.5.0 loguru-0.7.0 onnx-1.14.0\n"]}]},{"cell_type":"code","source":["#切换目录\n","%cd drive/MyDrive/Colab Notebooks/dddd_trainer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CAE2Lc_FwE4Q","executionInfo":{"status":"ok","timestamp":1690688150137,"user_tz":-480,"elapsed":2,"user":{"displayName":"沫茶子","userId":"03946290060744434733"}},"outputId":"c93d0370-61cf-4109-aa7c-46e79c6e6bd0"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/dddd_trainer\n"]}]},{"cell_type":"code","source":["# 确保在dddd_trainer目录\n","!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fjf3zHBRmg9U","executionInfo":{"status":"ok","timestamp":1690688154384,"user_tz":-480,"elapsed":800,"user":{"displayName":"沫茶子","userId":"03946290060744434733"}},"outputId":"79402054-4b06-4bf7-b36e-0fac6079614f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["app.py\t images   LICENSE  projects   requirements.txt\tutils\n","configs  images1  nets\t   README.md  tools\n"]}]},{"cell_type":"code","source":["# 生成缓存数据\n","!python app.py cache  AutoRunMap ./images/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R82XLSfoxw-S","executionInfo":{"status":"ok","timestamp":1690688181481,"user_tz":-480,"elapsed":23888,"user":{"displayName":"沫茶子","userId":"03946290060744434733"}},"outputId":"ce048b33-4887-4d4b-b4fc-c2ff2724d969"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[32m2023-07-30 03:36:17.766\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1m\n","Hello baby~\u001b[0m\n","\u001b[32m2023-07-30 03:36:17.768\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcache\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m\n","Caching Data ----> AutoRunMap\n","Path ----> ./images/\u001b[0m\n","\u001b[32m2023-07-30 03:36:17.788\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.cache_data\u001b[0m:\u001b[36m__get_label_from_name\u001b[0m:\u001b[36m36\u001b[0m - \u001b[1m\n","Files number is 1300.\u001b[0m\n","\r  0% 0/1300 [00:00<?, ?it/s]\r100% 1300/1300 [00:00<00:00, 540771.12it/s]\n","\u001b[32m2023-07-30 03:36:17.793\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.cache_data\u001b[0m:\u001b[36m__collect_data\u001b[0m:\u001b[36m92\u001b[0m - \u001b[1m\n","Coolect labels is [\" \", \"1\", \"6\", \"9\", \"3\", \"5\", \"8\", \"7\", \"2\", \"0\", \"4\"]\u001b[0m\n","\u001b[32m2023-07-30 03:36:17.801\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.cache_data\u001b[0m:\u001b[36m__collect_data\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1m\n","Writing Cache Data!\u001b[0m\n","\u001b[32m2023-07-30 03:36:17.802\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.cache_data\u001b[0m:\u001b[36m__collect_data\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1m\n","Cache Data Number is 1300\u001b[0m\n","\u001b[32m2023-07-30 03:36:17.802\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.cache_data\u001b[0m:\u001b[36m__collect_data\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m\n","Writing Train and Val File.\u001b[0m\n","\u001b[32m2023-07-30 03:36:18.851\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.cache_data\u001b[0m:\u001b[36m__collect_data\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1m\n","Train Data Number is 1261\u001b[0m\n","\u001b[32m2023-07-30 03:36:18.851\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.cache_data\u001b[0m:\u001b[36m__collect_data\u001b[0m:\u001b[36m117\u001b[0m - \u001b[1m\n","Val Data Number is 39\u001b[0m\n"]}]},{"cell_type":"code","source":["# 开始训练\n","# 符合 TARGET: {Accuracy: 0.99, Cost: 0.01, Epoch: 20} 条件才会导出 onnx 模型\n","!python app.py train AutoRunMap"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g-hdiNcUwKGh","outputId":"dfbc412f-240b-40c4-9efa-deff279c1e9b","executionInfo":{"status":"ok","timestamp":1690690843591,"user_tz":-480,"elapsed":73918,"user":{"displayName":"沫茶子","userId":"03946290060744434733"}}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[32m2023-07-30 04:19:31.201\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1m\n","Hello baby~\u001b[0m\n","\u001b[32m2023-07-30 04:19:31.202\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1m\n","Start Train ----> AutoRunMap\n","\u001b[0m\n","\u001b[32m2023-07-30 04:19:31.206\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.train\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m40\u001b[0m - \u001b[1m\n","Taget:\n","min_Accuracy: 0.99\n","min_Epoch: 20\n","max_Loss: 0.01\u001b[0m\n","\u001b[32m2023-07-30 04:19:31.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.train\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1m\n","USE GPU ----> 0\u001b[0m\n","\u001b[32m2023-07-30 04:19:31.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.train\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1m\n","Search for history checkpoints...\u001b[0m\n","\u001b[32m2023-07-30 04:19:31.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.train\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m69\u001b[0m - \u001b[1m\n","Empty history checkpoints\u001b[0m\n","\u001b[32m2023-07-30 04:19:31.208\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.train\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\n","Building Net...\u001b[0m\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","\u001b[32m2023-07-30 04:19:31.244\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.train\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mNet(\n","  (cnn): DdddOcr(\n","    (cnn): Sequential(\n","      (conv0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (relu0): ReLU(inplace=True)\n","      (pooling0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (relu1): ReLU(inplace=True)\n","      (pooling1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","      (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (batchnorm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu2): ReLU(inplace=True)\n","      (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (relu3): ReLU(inplace=True)\n","      (pooling2): MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n","      (conv4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (batchnorm4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu4): ReLU(inplace=True)\n","      (conv5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (relu5): ReLU(inplace=True)\n","      (pooling3): MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n","      (conv6): Conv2d(128, 128, kernel_size=(2, 2), stride=(1, 1))\n","      (batchnorm6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu6): ReLU(inplace=True)\n","    )\n","  )\n","  (lstm): LSTM(384, 384, dropout=0.3, bidirectional=True)\n","  (loss): CTCLoss()\n","  (fc): Linear(in_features=768, out_features=11, bias=True)\n",")\u001b[0m\n","\u001b[32m2023-07-30 04:19:31.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.train\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1m\n","Building End\u001b[0m\n","\u001b[32m2023-07-30 04:19:31.490\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.train\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1m\n","Get Data Loader...\u001b[0m\n","\u001b[32m2023-07-30 04:19:31.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.load_cache\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1m\n","Charsets is [\" \", \"1\", \"4\", \"0\", \"6\", \"2\", \"3\", \"8\", \"9\", \"7\", \"5\"]\u001b[0m\n","\u001b[32m2023-07-30 04:19:31.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.load_cache\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1m\n","Image Resize is [-1, 64]\u001b[0m\n","\u001b[32m2023-07-30 04:19:31.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.load_cache\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m118\u001b[0m - \u001b[1m\n","Image Path is ./images/\u001b[0m\n","\u001b[32m2023-07-30 04:19:31.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.load_cache\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m25\u001b[0m - \u001b[1m\n","Reading Cache File... ----> /content/drive/MyDrive/Colab Notebooks/dddd_trainer/projects/AutoRunMap/cache/cache.train.tmp\u001b[0m\n","\u001b[32m2023-07-30 04:19:31.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.load_cache\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1m\n","Read Cache File End! Caches Num is 1261.\u001b[0m\n","\u001b[32m2023-07-30 04:19:31.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.load_cache\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m25\u001b[0m - \u001b[1m\n","Reading Cache File... ----> /content/drive/MyDrive/Colab Notebooks/dddd_trainer/projects/AutoRunMap/cache/cache.val.tmp\u001b[0m\n","\u001b[32m2023-07-30 04:19:31.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.load_cache\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1m\n","Read Cache File End! Caches Num is 39.\u001b[0m\n","\u001b[32m2023-07-30 04:19:31.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.train\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1m\n","Get Data Loader End!\u001b[0m\n","\u001b[32m2023-07-30 04:19:39.232\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.train\u001b[0m:\u001b[36mstart\u001b[0m:\u001b[36m108\u001b[0m - \u001b[1m[2023-07-30-04_19_39]\tEpoch: 2\tStep: 100\tLastLoss: 2.4219324588775635\tAvgLoss: 3.1705613040924074\tLr: 0.01\u001b[0m\n","\u001b[32m2023-07-30 04:19:45.826\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.train\u001b[0m:\u001b[36mstart\u001b[0m:\u001b[36m108\u001b[0m - \u001b[1m[2023-07-30-04_19_45]\tEpoch: 5\tStep: 200\tLastLoss: 2.429487705230713\tAvgLoss: 2.5308001971244813\tLr: 0.01\u001b[0m\n","\u001b[32m2023-07-30 04:19:53.178\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.train\u001b[0m:\u001b[36mstart\u001b[0m:\u001b[36m108\u001b[0m - \u001b[1m[2023-07-30-04_19_53]\tEpoch: 7\tStep: 300\tLastLoss: 2.1411619186401367\tAvgLoss: 2.363794410228729\tLr: 0.01\u001b[0m\n","\u001b[32m2023-07-30 04:19:59.755\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.train\u001b[0m:\u001b[36mstart\u001b[0m:\u001b[36m108\u001b[0m - \u001b[1m[2023-07-30-04_19_59]\tEpoch: 10\tStep: 400\tLastLoss: 1.8071304559707642\tAvgLoss: 2.0054443955421446\tLr: 0.01\u001b[0m\n","\u001b[32m2023-07-30 04:20:07.139\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.train\u001b[0m:\u001b[36mstart\u001b[0m:\u001b[36m108\u001b[0m - \u001b[1m[2023-07-30-04_20_07]\tEpoch: 12\tStep: 500\tLastLoss: 1.0214970111846924\tAvgLoss: 1.480471431016922\tLr: 0.01\u001b[0m\n","\u001b[32m2023-07-30 04:20:13.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.train\u001b[0m:\u001b[36mstart\u001b[0m:\u001b[36m108\u001b[0m - \u001b[1m[2023-07-30-04_20_13]\tEpoch: 15\tStep: 600\tLastLoss: 0.6198796033859253\tAvgLoss: 0.8482235872745514\tLr: 0.01\u001b[0m\n","\u001b[32m2023-07-30 04:20:21.161\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.train\u001b[0m:\u001b[36mstart\u001b[0m:\u001b[36m108\u001b[0m - \u001b[1m[2023-07-30-04_20_21]\tEpoch: 17\tStep: 700\tLastLoss: 0.15594372153282166\tAvgLoss: 0.3239637937396765\tLr: 0.01\u001b[0m\n","\u001b[32m2023-07-30 04:20:27.745\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.train\u001b[0m:\u001b[36mstart\u001b[0m:\u001b[36m108\u001b[0m - \u001b[1m[2023-07-30-04_20_27]\tEpoch: 20\tStep: 800\tLastLoss: 0.04459250718355179\tAvgLoss: 0.08589232042431831\tLr: 0.01\u001b[0m\n","\u001b[32m2023-07-30 04:20:35.101\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.train\u001b[0m:\u001b[36mstart\u001b[0m:\u001b[36m108\u001b[0m - \u001b[1m[2023-07-30-04_20_35]\tEpoch: 23\tStep: 900\tLastLoss: 0.03343373164534569\tAvgLoss: 0.03643370334059\tLr: 0.01\u001b[0m\n","\u001b[32m2023-07-30 04:20:41.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.train\u001b[0m:\u001b[36mstart\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1m[2023-07-30-04_20_41]\tEpoch: 25\tStep: 1000\tLastLoss: 0.015174934640526772\tAvgLoss: 0.02163233397528529\tLr: 0.01\tAcc: 1.0\u001b[0m\n","\u001b[32m2023-07-30 04:20:41.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.train\u001b[0m:\u001b[36mstart\u001b[0m:\u001b[36m143\u001b[0m - \u001b[1m\n","Training Finished!Exporting Model...\u001b[0m\n","/usr/local/lib/python3.10/dist-packages/torch/onnx/symbolic_opset9.py:4476: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n","  warnings.warn(\n","============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n","verbose: False, log level: Level.ERROR\n","======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n","\n","\u001b[32m2023-07-30 04:20:42.114\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.train\u001b[0m:\u001b[36mstart\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1m\n","Export Finished!Using Time: 1.1666666666666667min\u001b[0m\n"]}]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1gWdV8-rjhz_sXw_cU-CkvywlOZhsVBRF","authorship_tag":"ABX9TyOCrxuVa34bGheJ/RNNvnWU"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}